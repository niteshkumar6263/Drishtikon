# Drishtikon

# ğŸ§  AI-Powered Blind Navigation System  
*"Empowering the visually impaired with real-time vision and voice."*

This project is a **wearable AI-powered assistive system** designed to help visually impaired individuals **navigate streets safely and independently**. It combines **YOLO(deep learning)** for object detection, **lane detection** using classical computer vision, and **real-time text-to-speech** feedback to describe obstacles and guide the user's direction.
This system acts as a **virtual assistant**, providing spoken instructions.

---

## ğŸ¯ Problem Statement

Over **285 million people** worldwide live with visual impairments. Most rely on white canes or guide dogs, which offer **limited awareness of their surroundings**. In busy urban environments, these traditional tools fail to detect:
- Incoming vehicles
- Obstacles like benches or stop signs
- Lanes 

There is a need for **affordable, real-time, intelligent navigation systems** that can fill this gap â€” and this project is a step toward that.

---

## ğŸ’¡ Solution Overview

This project brings together AI and assistive tech to deliver:
- **Visual sensing** using a chest-mounted
- **Object detection** (cars, people, traffic signs) using YOLOv8
- **Lane detection** for navigation guidance
- **Speech output** to notify the user of threats, objects, and directions
- **Distance estimation** to prioritize nearby obstacles

The user receives **spoken navigation cues** in real time, enabling them to:
- Avoid obstacles
- Understand direction
- Walk safely and confidently

---

## âœ¨ Key Features

| Feature | Description |
|--------|-------------|
| ğŸ§ Object Detection | Detects people, cars, buses, traffic lights, animals, etc. |
| ğŸ›£ï¸ Lane Detection |
| ğŸ—£ï¸ Audio Guidance | Speaks alerts like â€œBus aheadâ€, â€œTurn leftâ€ |
| ğŸ¥ Video Input | Works on live webcam |

---

## ğŸ§ª Technology Stack

### ğŸ” Vision & AI
- **YOLOv8 (Ultralytics)** â€“ Object detection on video frames
- **OpenCV** â€“ Lane detection using Canny + Hough Transform

### ğŸ—£ï¸ Audio & Speech
- **pyttsx3** â€“ Offline, cross-platform text-to-speech engine
- **Threading + Queue** â€“ Non-blocking speech processing

### ğŸ§  Logic & Control
- **NumPy** â€“ Image and distance calculations
- **Custom logic** â€“ For threat filtering, direction inference, and visual overlay

---

## ğŸ” How It Works

1. **Video is captured** (via webcam)
2. **YOLOv8** detects all visible objects and estimates distance
3. **OpenCV** performs edge and line detection to identify lanes
4. **Position logic** decides what the user should do next (turn, stop, walk)
5. **pyttsx3** gives voice instructions to the user
